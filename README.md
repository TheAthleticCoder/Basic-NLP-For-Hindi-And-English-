#NLP tools and Word Cloud generation
In this project, we perform:
A. Corpus Collection : We take around 10,000 sentences each from English and Hindi.
a. We web crawl to extract the text from approved Wikipedia articles.
b. Clean the corpus (Remove images, ads).
c. Remove foreign words/expressions, punctuations, symbols like currency, abbreviations. 
d. Acronyms (WHO, UNICEF) can be retained.
B. Perform the following on the corpus. We account for the 'Stop Words' as well
a. Tokenization (Sentences,Words).
b. POS tagging.
d. Stemming and Lemmatization
C. Analysis using computational tools.
a. Frequency graphs for each of the above tasks. 
b. Based on the Frequency analysis, we generate our own Word Clouds.
